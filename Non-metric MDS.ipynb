{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.utils import check_random_state, check_array, check_symmetric\n",
    "#from sklearn.externals.joblib import Parallel, delayed, effective_n_jobs\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "def NMDSfunc(dissimilarities, n_dimensions=2, max_iter=300, verbose=False, eps=1e-3, random_state=None):\n",
    "    '''\n",
    "    dissimilarities: matrix\n",
    "    eps: used for convergence\n",
    "    '''\n",
    "    dissimilarities = check_symmetric(dissimilarities, raise_exception=True)\n",
    "    n_samples = dissimilarities.shape[0]\n",
    "    random_state = check_random_state(random_state)\n",
    "\n",
    "    sim_flat = ((1 - np.tri(n_samples)) * dissimilarities).ravel()\n",
    "    sim_flat_w = sim_flat[sim_flat != 0]\n",
    "    #Random initial configuration\n",
    "    X = random_state.rand(n_samples * n_dimensions)\n",
    "    X = X.reshape((n_samples, n_dimensions))\n",
    "\n",
    "    old_stress = None\n",
    "    ir = IsotonicRegression()\n",
    "    for it in range(max_iter):\n",
    "        # Compute distance and monotonic regression\n",
    "        dis = euclidean_distances(X)\n",
    "        dis_flat = dis.ravel()\n",
    "        dis_flat_w = dis_flat[sim_flat != 0]\n",
    "\n",
    "        # Finf disparities using monotonic regression\n",
    "        disparities_flat = ir.fit_transform(sim_flat_w, dis_flat_w)\n",
    "        disparities = dis_flat.copy()\n",
    "        disparities[sim_flat != 0] = disparities_flat\n",
    "        disparities = disparities.reshape((n_samples, n_samples))\n",
    "        disparities *= np.sqrt((n_samples * (n_samples - 1) / 2) / (disparities ** 2).sum())\n",
    "        # Compute stress\n",
    "        stress = ((dis.ravel() - disparities.ravel()) ** 2).sum() / 2\n",
    "\n",
    "        # Update X using the Guttman transform\n",
    "        dis[dis == 0] = 1e-5\n",
    "        ratio = disparities / dis\n",
    "        B = - ratio\n",
    "        B[np.arange(len(B)), np.arange(len(B))] += ratio.sum(axis=1)\n",
    "        X = 1. / n_samples * np.dot(B, X)\n",
    "\n",
    "        dis = np.sqrt((X ** 2).sum(axis=1)).sum()\n",
    "        if verbose:\n",
    "            print('iteration: %d, stress %s' % (it, stress))\n",
    "        if old_stress is not None:\n",
    "            if(old_stress - stress / dis) < eps:\n",
    "                if verbose:\n",
    "                    print('convergence: breaking at iteration %d with stress %s' % (it,stress))\n",
    "                break\n",
    "        old_stress = stress / dis\n",
    "\n",
    "    return X, stress, it + 1\n",
    "\n",
    "\n",
    "def NMDS(dissimilarities, n_dimensions=2, n_init=4,\n",
    "            max_iter=300, verbose=False, eps=1e-3, random_state=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    dissimilarities = check_array(dissimilarities)\n",
    "    random_state = check_random_state(random_state)\n",
    "\n",
    "    best_pos, best_stress = None, None\n",
    "    for it in range(n_init):\n",
    "        pos, stress, n_iter_ = NMDSfunc(dissimilarities, n_dimensions=n_dimensions, max_iter=max_iter, verbose=verbose,\n",
    "                eps=eps, random_state=random_state)\n",
    "        print(pos)\n",
    "        print(stress)\n",
    "        if best_stress is None or stress < best_stress:\n",
    "            best_stress = stress\n",
    "            best_pos = pos.copy()\n",
    "            best_iter = n_iter_\n",
    "            \n",
    "    return best_pos, best_stress, best_iter\n",
    "\n",
    "\n",
    "class MDS():\n",
    "    def __init__(self, n_dimensions=2,  n_init=4,\n",
    "                 max_iter=300, verbose=False, eps=1e-3,\n",
    "                 random_state=None):\n",
    "        self.n_dimensions = n_dimensions\n",
    "        self.n_init = n_init\n",
    "        self.max_iter = max_iter\n",
    "        self.eps = eps\n",
    "        self.verbose = verbose\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "      \n",
    "        #self.fit_transform(X)\n",
    "        X = check_array(X)\n",
    "        self.dissimilarity_matrix_ = X\n",
    "        \n",
    "        self.embedding, self.stress, self.n_iter = NMDS(self.dissimilarity_matrix_,\n",
    "            n_dimensions=self.n_dimensions, n_init=self.n_init,\n",
    "            max_iter=self.max_iter, verbose=self.verbose,\n",
    "            eps=self.eps, random_state=self.random_state)\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.09929721 -0.67767375]\n",
      " [ 0.23075424  0.18620914]\n",
      " [-0.17561697  0.09403646]\n",
      " [ 0.0409847   0.38055228]]\n",
      "0.0109563293289\n",
      "[[-0.5541385   0.28148819]\n",
      " [ 0.35789969 -0.43610676]\n",
      " [ 0.13669892 -0.00865695]\n",
      " [ 0.05886924  0.16040147]]\n",
      "0.0125482922792\n",
      "[[-0.24872573 -0.13719767]\n",
      " [ 0.08729399 -0.35247961]\n",
      " [-0.32774578  0.32313976]\n",
      " [ 0.49749066  0.19927699]]\n",
      "0.0937225465117\n",
      "[[ 0.37078889 -0.42915919]\n",
      " [-0.17362818  0.46701517]\n",
      " [ 0.15403576  0.08859029]\n",
      " [-0.36925985 -0.13103964]]\n",
      "0.00540617827044\n"
     ]
    }
   ],
   "source": [
    "sim = np.array([[0, 5, 3, 4],\n",
    "                    [5, 0, 2, 2],\n",
    "                    [3, 2, 0, 1],\n",
    "                    [4, 2, 1, 0]])\n",
    "mds_clf = MDS()\n",
    "a = mds_clf.fit(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0054061782704412338"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.37078889, -0.42915919],\n",
       "       [-0.17362818,  0.46701517],\n",
       "       [ 0.15403576,  0.08859029],\n",
       "       [-0.36925985, -0.13103964]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
